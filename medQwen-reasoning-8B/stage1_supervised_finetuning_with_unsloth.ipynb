{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9fc2fe-c311-425a-b8e0-eca75201772c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from unsloth import FastLanguageModel\n",
    "from trl import SFTTrainer, SFTConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f326cafc-d490-4fc4-b3a4-7d2632b25f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "## config \n",
    "\n",
    "MODEL = \"unsloth/Qwen3-8B\"\n",
    "SFT_DATASET = \"FreedomIntelligence/medical-o1-reasoning-SFT\"\n",
    "OUTPUT_DIR = \"medQwen3-reasoning-8B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491aaa1f-ad2f-491c-b67c-6b889132b8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load dataset\n",
    "dataset = load_dataset(SFT_DATASET, \"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd577d2-8a16-4747-90e0-7ba499448551",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec38e96-7cbe-45c6-8134-073ae8f05e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acddbb3a-4eb5-496a-b90c-f13523c6613c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(example):\n",
    "    assistant_response = f\"\"\"\n",
    "<think>\n",
    "{example[\"Complex_CoT\"]}\n",
    "</think>\n",
    "\n",
    "<answer>\n",
    "{example[\"Response\"]}\n",
    "</answer>\"\"\"\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": example[\"Question\"]},\n",
    "            {\"role\": \"assistant\", \"content\": assistant_response}\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b084ff-0cb7-431a-a41d-15aca15d5821",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.map(preprocess_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48e203f-fe4f-4a96-b2bd-40277c944f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.remove_columns([\"Question\", \"Complex_CoT\", \"Response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8663a2c1-56b7-423c-8e78-871408170edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b381cd5c-5b6d-4575-8678-9d5d5aa8371a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Model and Lora Config\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = MODEL,\n",
    "    max_seq_length = 2048,\n",
    "    load_in_4bit = True, \n",
    "    fast_inference = True,\n",
    "    max_lora_rank = 16,\n",
    "    gpu_memory_utilization = 0.7,\n",
    ")\n",
    "\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16,\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
    "    lora_alpha = 32, # *2 speeds up training\n",
    "    use_gradient_checkpointing = \"unsloth\", \n",
    "    random_state = 42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9386afef-7fd8-4a9f-a048-cefbdb85641e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = \"\"\"\n",
    "{%- for message in messages %}\n",
    "    {%- if message['role'] == 'user' %}\n",
    "{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n' + message['content'] + '\\n\\n' %}\n",
    "{{ content }}\n",
    "    {%- elif message['role'] == 'assistant' %}\n",
    "{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n' + message['content'] + eos_token %}\n",
    "{{ content }}\n",
    "    {%- endif %}\n",
    "{%- endfor %}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634942a0-7593-4fce-bd72-4cbb4393fc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.chat_template = chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c139ca-06fe-4a51-9dec-d140710a889e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rendered = tokenizer.apply_chat_template(train_dataset[0][\"messages\"], tokenize=False, add_generation_prompt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c76cde-260f-4296-81a1-1de2ca55b625",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rendered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3643a4-a04a-498a-bbfd-4d7dc269f026",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.map(\n",
    "    lambda example: {\n",
    "        \"text\": tokenizer.apply_chat_template(example[\"messages\"], tokenize=False)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9bddb1-2bb8-464b-a90d-c17e6aaf44ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Even though, we are formatting the dataset beforehand, but when packing=True, it needs to have formatting_func.\n",
    "\n",
    "def formatting_func(example):\n",
    "    return example[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c410291-43cb-46c2-9abc-03f076cabba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SFFT Trainer\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = train_dataset,\n",
    "    max_seq_length = 8192,\n",
    "    formatting_func = formatting_func,\n",
    "    args = SFTConfig(\n",
    "        dataset_text_field=\"text\",\n",
    "        per_device_train_batch_size = 4,\n",
    "        gradient_accumulation_steps = 16,\n",
    "        num_train_epochs = 3, \n",
    "        warmup_steps = 100,\n",
    "        learning_rate = 2e-5,\n",
    "        logging_steps = 25,\n",
    "        optim = \"paged_adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=750,\n",
    "        save_total_limit=2,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 42,\n",
    "        output_dir = OUTPUT_DIR,\n",
    "        report_to = \"wandb\",\n",
    "        packing=False,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7ebe37-822f-4baa-82c9-7f546f9398b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9353f0-3b85-4c94-963e-03e257b01f1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
